{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Estimating COVID-19's $R_t$ in Real-Time with PYMC3\n",
    "\n",
    "Kevin Systrom - April 22\n",
    "\n",
    "Model originally built by [Thomas Vladeck](https://github.com/tvladeck) in Stan, parts inspired by the work over at https://epiforecasts.io/, lots of help from [Thomas Wiecki](https://twitter.com/twiecki). Thank you to everyone who helped.\n",
    "\n",
    "This notebook is a WIP - I'll add more context and commentary over the coming week."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import pymc3 as pm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import theano\n",
    "import theano.tensor as tt\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import dates as mdates\n",
    "from matplotlib import ticker\n",
    "\n",
    "from datetime import date\n",
    "from datetime import datetime\n",
    "\n",
    "from IPython.display import clear_output\n",
    "\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load State Information\n",
    "#### Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://covidtracking.com/api/v1/states/daily.csv'\n",
    "states = pd.read_csv(url,\n",
    "                     parse_dates=['date'],\n",
    "                     index_col=['state', 'date']).sort_index()\n",
    "\n",
    "# Note: GU/AS/VI do not have enough data for this model to run\n",
    "# Note: PR had -384 change recently in total count so unable to model\n",
    "states = states.drop(['MP', 'GU', 'AS', 'PR', 'VI'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clean data with known modifications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Washington removed 190 from their case count on 4/19\n",
    "states.loc[('WA', slice('2020-04-20',None)), 'positive'] += 190\n",
    "\n",
    "# Covidtracker has the wrong count according to the state website\n",
    "states.loc[('HI', '2020-04-22')] = 586\n",
    "\n",
    "# For some reason early on RI went negative and back to this value\n",
    "states.loc[('RI', '2020-03-07')] = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Integrity Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure that all the states have current data\n",
    "today = datetime.combine(date.today(), datetime.min.time())\n",
    "last_updated = states.reset_index('date').groupby('state')['date'].max()\n",
    "is_current = last_updated < today\n",
    "\n",
    "try:\n",
    "    assert is_current.sum() == 0\n",
    "except AssertionError:\n",
    "    print(\"Not all states have updated\")\n",
    "    display(last_updated[is_current])\n",
    "\n",
    "# Ensure all case diffs are greater than zero\n",
    "for state, grp in states.groupby('state'):\n",
    "    new_cases = grp.positive.diff().dropna()\n",
    "    is_positive = new_cases.ge(0)\n",
    "    \n",
    "    try:\n",
    "        assert is_positive.all()\n",
    "    except AssertionError:\n",
    "        print(f\"Warning: {state} has date with negative case counts\")\n",
    "        display(new_cases[~is_positive])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Patient Information\n",
    "#### Download\n",
    "~100mb download (be ... patient!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_file(url, local_filename):\n",
    "    \"\"\"From https://stackoverflow.com/questions/16694907/\"\"\"\n",
    "    with requests.get(url, stream=True) as r:\n",
    "        r.raise_for_status()\n",
    "        with open(local_filename, 'wb') as f:\n",
    "            for chunk in r.iter_content(chunk_size=8192): \n",
    "                if chunk: # filter out keep-alive new chunks\n",
    "                    f.write(chunk)\n",
    "    return local_filename\n",
    "\n",
    "\n",
    "URL = \"https://raw.githubusercontent.com/beoutbreakprepared/nCoV2019/master/latest_data/latestdata.csv\"\n",
    "LINELIST_PATH = 'data/linelist.csv'\n",
    "\n",
    "if not os.path.exists(LINELIST_PATH):\n",
    "    print('Downloading file, this will take a while ~100mb')\n",
    "    try:\n",
    "        download_file(URL, LINELIST_PATH)\n",
    "        clear_output(wait=True)\n",
    "        print('Done downloading.')\n",
    "    except:\n",
    "        print('Something went wrong. Try again.')\n",
    "else:\n",
    "    print('Already downloaded CSV')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Parse & Clean Patient Info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the patient CSV\n",
    "patients = pd.read_csv(\n",
    "    'data/linelist.csv',\n",
    "    parse_dates=False,\n",
    "    usecols=[\n",
    "        'date_confirmation',\n",
    "        'date_onset_symptoms'],\n",
    "    low_memory=False)\n",
    "\n",
    "patients.columns = ['Onset', 'Confirmed']\n",
    "\n",
    "# There's an errant reversed date\n",
    "patients = patients.replace('01.31.2020', '31.01.2020')\n",
    "\n",
    "# Only keep if both values are present\n",
    "patients = patients.dropna()\n",
    "\n",
    "# Must have strings that look like individual dates\n",
    "# \"2020.03.09\" is 10 chars long\n",
    "is_ten_char = lambda x: x.str.len().eq(10)\n",
    "patients = patients[is_ten_char(patients.Confirmed) & \n",
    "                    is_ten_char(patients.Onset)]\n",
    "\n",
    "# Convert both to datetimes\n",
    "patients.Confirmed = pd.to_datetime(\n",
    "    patients.Confirmed, format='%d.%m.%Y')\n",
    "patients.Onset = pd.to_datetime(\n",
    "    patients.Onset, format='%d.%m.%Y')\n",
    "\n",
    "# Only keep records where confirmed > onset\n",
    "patients = patients[patients.Confirmed >= patients.Onset]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Show Relationship between Onset of Symptoms and Confirmation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = patients.plot.scatter(\n",
    "    title='Onset vs. Confirmed Dates - COVID19',\n",
    "    x='Onset',\n",
    "    y='Confirmed',\n",
    "    alpha=.1,\n",
    "    lw=0,\n",
    "    s=10,\n",
    "    figsize=(6,6))\n",
    "\n",
    "formatter = mdates.DateFormatter('%m/%d')\n",
    "locator = mdates.WeekdayLocator(interval=2)\n",
    "\n",
    "for axis in [ax.xaxis, ax.yaxis]:\n",
    "    axis.set_major_formatter(formatter)\n",
    "    axis.set_major_locator(locator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculate the Probability Distribution of Delay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the delta in days between onset and confirmation\n",
    "delay = (patients.Confirmed - patients.Onset).dt.days\n",
    "\n",
    "# Convert samples to an empirical distribution\n",
    "p_delay = delay.value_counts().sort_index()\n",
    "new_range = np.arange(0, p_delay.index.max()+1)\n",
    "p_delay = p_delay.reindex(new_range, fill_value=0)\n",
    "p_delay /= p_delay.sum()\n",
    "\n",
    "# Show our work\n",
    "fig, axes = plt.subplots(ncols=2, figsize=(9,3))\n",
    "p_delay.plot(title='P(Delay)', ax=axes[0])\n",
    "p_delay.cumsum().plot(title='P(Delay <= x)', ax=axes[1])\n",
    "for ax in axes:\n",
    "    ax.set_xlabel('days')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A Single State\n",
    "\n",
    "#### Select State Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = 'CA'\n",
    "confirmed = states.xs(state).positive.diff().dropna()\n",
    "confirmed.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Translate Confirmation Dates to Onset Dates\n",
    "\n",
    "Our goal is to translate positive test counts to the dates where they likely occured. Since we have the distribution, we can distribute case counts back in time according to that distribution. To accomplish this, we reverse the case time series, and convolve it using the distribution of delay from onset to confirmation. Then we reverse the series again to obtain the onset curve. Note that this means the data will be 'right censored' which means there are onset cases that have yet to be reported so it looks as if the count has gone down."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def confirmed_to_onset(confirmed, p_delay):\n",
    "\n",
    "    assert not confirmed.isna().any()\n",
    "    \n",
    "    # Reverse cases so that we convolve into the past\n",
    "    convolved = np.convolve(confirmed[::-1].values, p_delay)\n",
    "\n",
    "    # Calculate the new date range\n",
    "    dr = pd.date_range(end=confirmed.index[-1],\n",
    "                       periods=len(convolved))\n",
    "\n",
    "    # Flip the values and assign the date range\n",
    "    onset = pd.Series(np.flip(convolved), index=dr)\n",
    "    \n",
    "    return onset\n",
    "\n",
    "\n",
    "onset = confirmed_to_onset(confirmed, p_delay)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adjust for Right-Censoring\n",
    "\n",
    "Since we distributed observed cases into the past to recreate the onset curve, we now have a right-censored time series. We can correct for that by asking what % of people have a delay less than or equal to the time between the day in question and the current day.\n",
    "\n",
    "For example, 5 days ago, there might have been 100 cases onset. Over the course of the next 5 days some portion of those cases will be reported. This portion is equal to the cumulative distribution function of our delay distribution. If we know that portion is say, 60%, then our current count of onset on that day represents 60% of the total. This implies that the total is 166% higher. We apply this correction to get an idea of what actual onset cases are likely, thus removing the right censoring."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjust_onset_for_right_censorship(onset, p_delay):\n",
    "    cumulative_p_delay = p_delay.cumsum()\n",
    "    \n",
    "    # Calculate the additional ones needed so shapes match\n",
    "    ones_needed = len(onset) - len(cumulative_p_delay)\n",
    "    padding_shape = (0, ones_needed)\n",
    "    \n",
    "    # Add ones and flip back\n",
    "    cumulative_p_delay = np.pad(\n",
    "        cumulative_p_delay,\n",
    "        padding_shape,\n",
    "        constant_values=1)\n",
    "    cumulative_p_delay = np.flip(cumulative_p_delay)\n",
    "    \n",
    "    # Adjusts observed onset values to expected terminal onset values\n",
    "    adjusted = onset / cumulative_p_delay\n",
    "    \n",
    "    return adjusted, cumulative_p_delay\n",
    "\n",
    "\n",
    "adjusted, cumulative_p_delay = adjust_onset_for_right_censorship(onset, p_delay)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take a look at all three series: confirmed, onset and onset adjusted for right censoring."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(5,3))\n",
    "\n",
    "confirmed.plot(\n",
    "    ax=ax,\n",
    "    label='Confirmed',\n",
    "    title=state,\n",
    "    c='k',\n",
    "    alpha=.25,\n",
    "    lw=1)\n",
    "\n",
    "onset.plot(\n",
    "    ax=ax,\n",
    "    label='Onset',\n",
    "    c='k',\n",
    "    lw=1)\n",
    "\n",
    "adjusted.plot(\n",
    "    ax=ax,\n",
    "    label='Adjusted Onset',\n",
    "    c='k',\n",
    "    linestyle='--',\n",
    "    lw=1)\n",
    "\n",
    "ax.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have the model run on days where we have enough data ~last 50 or so"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample the Posterior with PyMC3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We assume a poisson likelihood function and feed it what we believe is the onset curve based on reported data. We model this onset curve based on the same math in the previous notebook:\n",
    "\n",
    "$$ I^\\prime = Ie^{\\gamma(R_t-1)} $$\n",
    "\n",
    "We define $\\theta = \\gamma(R_t-1)$ and model $ I^\\prime = Ie^{\\theta} $ where $\\theta$ observes a random walk. We let $\\gamma$ vary independently based on known parameters for the serial interval. Therefore, we can recover $R_t$ easily by $R_t = \\frac{\\theta}{\\gamma}+1$\n",
    "\n",
    "The only tricky part is understanding that we're feeding in _onset_ cases to the likelihood. So $\\mu$ of the poisson is the positive, non-zero, expected onset cases we think we'd see today.\n",
    "\n",
    "We calculate this by figuring out how many cases we'd expect there to be yesterday total when adjusted for bias and plugging it into the first equation above. We then have to re-bias this number back down to get the expected amount of onset cases observed that day."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MCMCModel(object):\n",
    "    \n",
    "    def __init__(self, region, onset, cumulative_p_delay, window=50):\n",
    "        \n",
    "        # Just for identification purposes\n",
    "        self.region = region\n",
    "        \n",
    "        # For the model, we'll only look at the last N\n",
    "        self.onset = onset.iloc[-window:]\n",
    "        self.cumulative_p_delay = cumulative_p_delay[-window:]\n",
    "        \n",
    "        # Where we store the results\n",
    "        self.trace = None\n",
    "        self.trace_index = self.onset.index[1:]\n",
    "\n",
    "    def run(self, chains=1, tune=3000, draws=1000, target_accept=.95):\n",
    "\n",
    "\n",
    "        with pm.Model() as model:\n",
    "\n",
    "            # Random walk magnitude\n",
    "            step_size = pm.HalfNormal('step_size', sigma=.03)\n",
    "\n",
    "            # Theta random walk\n",
    "            theta_raw_init = pm.Normal('theta_raw_init', 0.1, 0.1)\n",
    "            theta_raw_steps = pm.Normal('theta_raw_steps', shape=len(self.onset)-2) * step_size\n",
    "            theta_raw = tt.concatenate([[theta_raw_init], theta_raw_steps])\n",
    "            theta = pm.Deterministic('theta', theta_raw.cumsum())\n",
    "\n",
    "            # Let the serial interval be a random variable and calculate r_t\n",
    "            serial_interval = pm.Gamma('serial_interval', alpha=6, beta=1.5)\n",
    "            gamma = 1.0/serial_interval\n",
    "            r_t = pm.Deterministic('r_t', theta/gamma + 1)\n",
    "\n",
    "            inferred_yesterday = self.onset.values[:-1] / self.cumulative_p_delay[:-1]\n",
    "            \n",
    "            expected_today = inferred_yesterday * self.cumulative_p_delay[1:] * pm.math.exp(theta)\n",
    "\n",
    "            # Ensure cases stay above zero for poisson\n",
    "            mu = pm.math.maximum(.1, expected_today)\n",
    "            observed = self.onset.round().values[1:]\n",
    "            cases = pm.Poisson('cases', mu=mu, observed=observed)\n",
    "\n",
    "            self.trace = pm.sample(\n",
    "                chains=chains,\n",
    "                tune=tune,\n",
    "                draws=draws,\n",
    "                target_accept=target_accept)\n",
    "            \n",
    "            return self"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Pymc3 Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {}\n",
    "\n",
    "for state, grp in states.groupby('state'):\n",
    "    \n",
    "    print(state)\n",
    "    \n",
    "    if state in models:\n",
    "        print(f'Skipping {state}, already in cache')\n",
    "        continue\n",
    "    \n",
    "    confirmed = grp.droplevel(0).positive.diff().dropna()\n",
    "    onset = confirmed_to_onset(confirmed, p_delay)\n",
    "    adjusted, cumulative_p_delay = adjust_onset_for_right_censorship(onset, p_delay)\n",
    "    models[state] = MCMCModel(state, onset, cumulative_p_delay).run()\n",
    "    \n",
    "    # Check to see if there were divergences, if so stop.\n",
    "\n",
    "    diverging = models[state].trace['diverging']\n",
    "    n_diverging = diverging.nonzero()[0].size\n",
    "    if n_diverging:\n",
    "        print(f'\\t{n_diverging} divergences, stopping loop for debugging')\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = None\n",
    "\n",
    "for state, model in models.items():\n",
    "\n",
    "    r_t = model.trace['r_t']\n",
    "    mean = np.mean(r_t, axis=0)\n",
    "    hpd_90 = pm.stats.hpd(r_t, credible_interval=.9)\n",
    "    hpd_50 = pm.stats.hpd(r_t, credible_interval=.5)\n",
    "    \n",
    "    idx = pd.MultiIndex.from_product([\n",
    "            [state],\n",
    "            model.trace_index\n",
    "        ], names=['state', 'date'])\n",
    "        \n",
    "    df = pd.DataFrame(data=np.c_[mean, hpd_90, hpd_50], index=idx,\n",
    "                 columns=['ML', 'Low_90', 'High_90', 'Low_50','High_50'])\n",
    "    \n",
    "    if results is None:\n",
    "        results = df\n",
    "    else:\n",
    "        results = pd.concat([results, df],axis=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Render to CSV\n",
    "Uncomment if you'd like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#results.to_csv('data/rt_mcmc.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Render Graphics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_rt(name, result, ax):\n",
    "    ax.set_ylim(0.6,1.55)\n",
    "    ax.set_title(name)\n",
    "    ax.plot(result['ML'],\n",
    "            marker='o',\n",
    "            markersize=4,\n",
    "            markerfacecolor='w',\n",
    "            lw=1,\n",
    "            c=(.3,.3,.3,1),\n",
    "            markevery=2)\n",
    "    ax.fill_between(\n",
    "        result.index,\n",
    "        result['Low_90'].values,\n",
    "        result['High_90'].values,\n",
    "        color='k',\n",
    "        alpha=.05,\n",
    "        lw=0)\n",
    "    ax.axhline(1.0, linestyle=':', lw=1)\n",
    "    \n",
    "    ax.xaxis.set_major_formatter(mdates.DateFormatter('%m/%d'))\n",
    "    ax.xaxis.set_major_locator(mdates.WeekdayLocator(interval=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ncols = 5\n",
    "nrows = int(np.ceil(results.index.levels[0].shape[0]) / ncols)\n",
    "\n",
    "fig, axes = plt.subplots(nrows=nrows, ncols=ncols, figsize=(15, nrows*3), sharey='row')\n",
    "\n",
    "for ax, (state,result) in zip(axes.flat, results.groupby('state')):\n",
    "    result = result.droplevel(0)\n",
    "    plot_rt(state, result, ax)\n",
    "\n",
    "fig.tight_layout()\n",
    "fig.set_facecolor('w')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
